{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "from sht_utils import *\n",
    "from subs1_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Spectral Truncation Desired and Consistent\n",
    "###    Gausian Grid\n",
    "zw = 42\n",
    "kmax = 11\n",
    "###\n",
    "###\n",
    "cmap = 'turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value for kmax.\n",
    "if kmax!=11 and kmax!=26:\n",
    "    raise Exception(\"Unexpected value for kmax\")\n",
    "\n",
    "# Check value for zw.\n",
    "# Afterwards, set mw, jmax, and imax values based on the value given to zw.\n",
    "match zw:\n",
    "    case 42:\n",
    "        mw = zw\n",
    "        jmax = 64\n",
    "        imax = 128\n",
    "    case 63:\n",
    "        mw = zw\n",
    "        jmax = 96\n",
    "        imax = 192\n",
    "    case 124:\n",
    "        mw = zw\n",
    "        jmax = 188\n",
    "        imax = 376\n",
    "    case _:\n",
    "        raise Exception(\"Unexpected value for zw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name a path in which to save the preprocess output files.\n",
    "preprocess_path = (\n",
    "    'preprocess'\n",
    "    + '__zw_' + str(zw)\n",
    "    + '__kmax_' + str(kmax)\n",
    "    + '\\\\'\n",
    ")\n",
    "\n",
    "# Create an appropriate datapath for the user's operating system.\n",
    "# Delete and recreate the path if it already existed.\n",
    "cwd = str(pathlib.Path().resolve()) + '\\\\'\n",
    "user_platform = platform.system()\n",
    "print(\"Setting output preprocess_path for\", user_platform)\n",
    "match user_platform:\n",
    "    case 'Windows':\n",
    "        subprocess.run(['rmdir', '/s', '/q', cwd+preprocess_path], shell=True)\n",
    "        subprocess.run(['mkdir', cwd+preprocess_path], shell=True)\n",
    "    case 'Darwin':\n",
    "        subprocess.call(['rm','-r', cwd+preprocess_path])\n",
    "        subprocess.check_output(['mkdir', cwd+preprocess_path])\n",
    "    case _:\n",
    "        raise Exception(\"Use case for this system/OS is not implemented.\")\n",
    "print(\"preprocess_path =\", preprocess_path)\n",
    "print(\"fullpath = \", cwd+preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab Topography Data\n",
    "###\n",
    "url_topo = 'http://research.jisao.washington.edu/data_sets/elevation/elev.0.75-deg.nc'\n",
    "ds_topo = xr.open_dataset(url_topo + '#mode=bytes', decode_times = False) # adding #mode=bytes because netcdf4 non-opendap URLrequeriment\n",
    "del ds_topo['time']\n",
    "data = ds_topo.data.squeeze()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.linspace(-np.pi, np.pi, data.shape[1])\n",
    "lat = np.linspace(np.pi/2., -np.pi/2., data.shape[0])\n",
    "Lon, Lat = np.meshgrid(lon, lat)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection='mollweide')\n",
    "cs = ax.pcolormesh(Lon, Lat, data, cmap=cmap)\n",
    "ax.set_title(\"Elevation map 0.75â—¦\")\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "fig.colorbar(cs, ax=ax, shrink=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup necessary element for interpolation onto model Gaussian Grid\n",
    "#\n",
    "# First get the Gaussian latitudes on equally spaced longitudes\n",
    "#\n",
    "cost_lg, wlg = legendre_gauss_weights(jmax, -1, 1)\n",
    "lats = np.flip(np.arccos(cost_lg))\n",
    "lats = -90+180*lats/(np.pi)\n",
    "#\n",
    "lons = np.linspace(0.0,360.0-360.0/imax,imax)\n",
    "#\n",
    "# foo below is used for interpolation\n",
    "#\n",
    "foo = np.zeros((jmax,imax))\n",
    "dfoo = xr.Dataset({'foo': (['lat','lon'],foo)},\n",
    "                    coords={'lat': lats, 'lon': lons})\n",
    "#\n",
    "regridder_oi = xe.Regridder(data,dfoo,'bilinear')\n",
    "regridder_oi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg = regridder_oi(data)*9.8\n",
    "topog_gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg = np.where(topog_gg < 0.0, 0.0, topog_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, topog_gg, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg_dev = torch.from_numpy(topog_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate Transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "sht = RealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "isht = InverseRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "vsht = RealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "ivsht = InverseRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = sht(topog_gg_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg_r = isht(coeffs).cpu()\n",
    "topog_gg_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, topog_gg_r, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = (torch.from_numpy(topog_gg) - topog_gg_r)\n",
    "plt.pcolormesh(Lon, Lat, foo, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the spectral coefficients for topography to be read by\n",
    "# the AGCM as a pickle file\n",
    "#\n",
    "torch.save(coeffs,preprocess_path+'topog.spectral.pt') # South - to - North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Surface temp used to derive 3-D temperature field for\n",
    "# Newtonian Relaxation\n",
    "#\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/surface/air.sig995.mon.mean.nc'\n",
    "Dtemp = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dtemp\n",
    "#\n",
    "# Field above is monthly 0.995 sigma level data\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtemp.air[100,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Need to set up vertical structure of back-ground temp based on\n",
    "# first sigma level in put. Will need model vertical structure\n",
    "# from subs1_utils\n",
    "#\n",
    "# First Calculate Climatology\n",
    "#\n",
    "tsurf_climo = Dtemp.air.groupby('time.month').mean(dim='time')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then interpolate to Gaussian grid\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(tsurf_climo[1,:,:],dfoo,'bilinear')\n",
    "#\n",
    "tsurf_feb = regridder_oi2(tsurf_climo[1,:,:])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf_feb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf_feb_zonalmean = tsurf_feb.mean(dim='lon')\n",
    "tsurf_feb_zonalmean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now generature the vertical strucuture of temperature\n",
    "# will neeed model vertical structure (si(kmax))\n",
    "#\n",
    "#\n",
    "delsig, si, sl, sikap, slkap, cth1, cth2, r1b, r2b = bscst(kmax)\n",
    "#\n",
    "#\n",
    "temp_spec = torch.from_numpy(np.zeros((kmax,zw,mw)))\n",
    "temp_gg = np.zeros((kmax,jmax,imax))\n",
    "#\n",
    "#   Radiative equilibrium temperature\n",
    "#       varying surface temperature decreasing with\n",
    "#       height with a lapse rate dTe/dz approx = -rlaps degrees/m\n",
    "#       to a stratospheric temperature of tstrat\n",
    "#\n",
    "rlaps=6.8*1.0e-03\n",
    "h0 = 8.2e+03\n",
    "tstrat = 205.0 # fixed stratospheric temperature\n",
    "#\n",
    "#for ii in range(imax):\n",
    "#    temp_gg[kmax-1,:,ii] = tsurf_feb_zonalmean[:].values + 273.16 # Uncomment if\n",
    "                                                        # only using zonal mean surface\n",
    "                                                        # temperature\n",
    "temp_gg[kmax-1,:,:] = tsurf_feb.values + 273.16 # Uncomment if using full surface \n",
    "                                                 # temperature\n",
    "for k in np.arange(1, kmax, 1, dtype=int):\n",
    "    temp_gg[k,:,:] = temp_gg[kmax-1,:,:] + h0*rlaps*np.log(sl[k])\n",
    "#\n",
    "temp_gg = np.where(temp_gg < 205.0, 205.0, temp_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(Lon, Lat, temp_gg[10,:,:]-273.16, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coeffs = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "for k in range(kmax):\n",
    "    tmp = torch.from_numpy(temp_gg[k])\n",
    "    temp_coeffs[k] = sht(tmp).cpu() # South-to-North same as topog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(temp_coeffs,preprocess_path+'temp.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/surface_gauss/pres.sfc.mon.mean.nc'\n",
    "Dps = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psmean = Dps.pres.groupby('time.month').mean(dim='time')\n",
    "(psmean[1]/100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnps = np.log(psmean[1]/(1000*100))\n",
    "lnps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then interpolate to Gaussian grid\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(lnps,dfoo,'bilinear')\n",
    "#\n",
    "lnps_feb = regridder_oi2(lnps)\n",
    "lnps_feb.plot()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.from_numpy(lnps_feb.values)\n",
    "lnps_coeffs = sht(tmp).cpu()\n",
    "torch.save(lnps_coeffs,preprocess_path+'lnps.spectral.pt') # South-to-North same as topog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# possible prescribed heating\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/cmap/enh/precip.mon.mean.nc'\n",
    "Dprec = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dprec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "prec_clim = Dprec.precip.groupby('time.month').mean(dim='time')\n",
    "prec_anom = Dprec.precip.groupby('time.month') - prec_clim\n",
    "#\n",
    "# ENSO Warm years\n",
    "wyrs = ['1983','1987','1988','1992','1995','1998','2003','2005','2007','2010','2015','2016','2019']\n",
    "anom = prec_anom[0]*0.0\n",
    "for k in range(13):\n",
    "    anom = anom + prec_anom.sel(time=wyrs[k]+'-02-01')\n",
    "rain_anom = anom/13.0\n",
    "rain_anom.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert rainfall anomaly into a hearting rate that can\n",
    "# applied to the temperature equation (i.e., Q/Cp) and distribute\n",
    "# in the vertical\n",
    "#\n",
    "vert_struc = np.zeros(kmax) # whatever user wants\n",
    "#                                 kmax is lowest level and\n",
    "#                                 0 is the upper most level of\n",
    "#                                 the atmosphere\n",
    "heat = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "#\n",
    "if (kmax == 11):\n",
    "    vert_struc[0] = 0.0\n",
    "    vert_struc[1] = 0.1\n",
    "    vert_struc[2] = 0.2\n",
    "    vert_struc[3] = 1.5\n",
    "    vert_struc[4] = 1.9\n",
    "    vert_struc[5] = 1.5\n",
    "    vert_struc[6] = 0.9\n",
    "    vert_struc[7] = 0.5\n",
    "    vert_struc[8] = 0.2\n",
    "    vert_struc[9] = 0.1\n",
    "    vert_struc[10] = 0.0\n",
    "#\n",
    "if (kmax == 26):\n",
    "    vert_struc[0] = 0.0\n",
    "    vert_struc[1] = 0.0\n",
    "    vert_struc[2] = 0.0\n",
    "    vert_struc[3] = 0.0\n",
    "    vert_struc[4] = 0.0\n",
    "    vert_struc[5] = 0.0\n",
    "    vert_struc[6] = 0.0\n",
    "    vert_struc[7] = 0.0\n",
    "    vert_struc[8] = 0.0\n",
    "    vert_struc[9] = 0.0\n",
    "    vert_struc[10] = 0.0\n",
    "    vert_struc[11] = 0.0\n",
    "    vert_struc[12] = 0.0\n",
    "    vert_struc[13] = 0.0\n",
    "    vert_struc[14] = 0.25\n",
    "    vert_struc[15] = 0.5\n",
    "    vert_struc[16] = 1.75\n",
    "    vert_struc[17] = 1.75\n",
    "    vert_struc[18] = 1.75\n",
    "    vert_struc[19] = 1.75\n",
    "    vert_struc[20] = 1.75\n",
    "    vert_struc[21] = 1.75\n",
    "    vert_struc[22] = 1.5\n",
    "    vert_struc[23] = 0.75\n",
    "    vert_struc[24] = 0.0\n",
    "    vert_struc[25] = 0.0\n",
    "#\n",
    "# Need to ensure that vertical integral normalizes to 1.0\n",
    "rnorm = (vert_struc*delsig).sum()\n",
    "vert_struc = vert_struc/rnorm\n",
    "#\n",
    "# interpolate to Gaussian grid\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(rain_anom,dfoo,'bilinear')\n",
    "#\n",
    "tmp = regridder_oi2(rain_anom)\n",
    "tmp = np.where(tmp < 0.0, 0.0, tmp)\n",
    "tmp_hold = tmp\n",
    "#\n",
    "#\n",
    "# convert to heating and multiple by vertical structure\n",
    "#\n",
    "Lv = 2.5e+06\n",
    "rhow = 1000.0\n",
    "Cp = 1005.0\n",
    "Ps = 101325.0\n",
    "grav = 9.8\n",
    "beta = (Lv*rhow/Cp)*(grav/Ps)/(1000.0*86400.0)\n",
    "tropics = np.exp((-Lat*Lat)/700.0) # limit forcing to tropics\n",
    "tmp = tropics*tmp\n",
    "#\n",
    "# Transform forward and backward to reduce forcing at unresolved scales\n",
    "#\n",
    "tmpspec = sht(torch.from_numpy(tmp))\n",
    "tmp = isht(tmpspec)\n",
    "#\n",
    "for k in range(kmax):\n",
    "    heat[k,:,:] = (tmp[:,:]*vert_struc[k]*beta) # in K/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.pcolormesh(Lon, Lat, heat[10], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.pcolormesh(Lon, Lat, tmp-tmp_hold, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "torch.save(heat,preprocess_path+'heat.ggrid.pt') # South-to-North same as topog data\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The remaining cells only need to be executed if prescribed background\n",
    "# state is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def press_to_sig(kmax,imax,jmax,press_data,press_levels,ps,slmodel,kmax_model):\n",
    "    # \n",
    "    # first convert pressure data to sigma using ps\n",
    "    #\n",
    "    sig_levels = torch.zeros((kmax,jmax,imax),dtype=torch.float64) # sigma levels of input data\n",
    "    sig_data = torch.zeros((kmax_model,jmax,imax),dtype=torch.float64) # output on model sigma levels\n",
    "    slmap = torch.zeros((kmax_model,jmax,imax),dtype=torch.float64) # model sigma levels but for all j & i\n",
    "    for k in range(kmax):\n",
    "        sig_levels[k,:,:] = press_levels[k]/ps[:,:] # sig_levels depends on k,j & i\n",
    "    for k in range(kmax_model):\n",
    "        slmap[k,:,:] = torch.tensor(slmodel[k]) \n",
    "    #\n",
    "    # now at each j & i to interpolate to the appropriate model sigma level\n",
    "    # Use log(sig) for interpolation\n",
    "    #\n",
    "    for isig in range(kmax_model):\n",
    "        for ipress in np.arange(kmax-1, -1, -1, dtype=int):\n",
    "            foo_up = torch.gt(slmap[isig],sig_levels[ipress-1])\n",
    "            foo_dn = torch.lt(slmap[isig],sig_levels[ipress])\n",
    "            # test if appropriate press level found\n",
    "            foo_up = 1*foo_up\n",
    "            foo_dn = 1*foo_dn\n",
    "            foo = foo_up + foo_dn\n",
    "            found = ( foo == 2 )\n",
    "            found = 1*found\n",
    "            ### found = 1 level found ; found = 0 level not found\n",
    "            denom = torch.log(sig_levels[ipress])\\\n",
    "                            - torch.log(sig_levels[ipress-1])\n",
    "            numer1 = torch.log(sig_levels[ipress])\\\n",
    "                            - torch.log(slmap[isig])\n",
    "            numer2 = torch.log(slmap[isig])\\\n",
    "                            - torch.log(sig_levels[ipress-1])\n",
    "            foo = numer1*press_data[ipress-1]/denom + numer2*press_data[ipress]/denom\n",
    "            sig_data[isig] = found*(foo) + (1-found)*sig_data[isig]\n",
    "    #\n",
    "    #\n",
    "    # Need to check if model sigma level is below reanalysis lowest sigma level\n",
    "    #\n",
    "    for isig in range(kmax_model):\n",
    "        foo_dn = torch.gt(slmap[isig],sig_levels[kmax-1])\n",
    "        foo_dn = 1*foo_dn\n",
    "        sig_data[isig] = foo_dn*press_data[kmax-1] + (1-foo_dn)*sig_data[isig]\n",
    "    #\n",
    "    return sig_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The remaining cells only need to be executed if prescribed background\n",
    "# state is being used\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/vwnd.mon.mean.nc'\n",
    "Dvwnd = xr.open_dataset(ftemp,autoclose=True)\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/uwnd.mon.mean.nc'\n",
    "Duwnd = xr.open_dataset(ftemp,autoclose=True)\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/air.mon.mean.nc'\n",
    "Dair = xr.open_dataset(ftemp,autoclose=True)\n",
    "uwnd_clim = Duwnd.uwnd.groupby('time.month').mean(dim='time')\n",
    "vwnd_clim = Dvwnd.vwnd.groupby('time.month').mean(dim='time')\n",
    "air_clim = Dair.air.groupby('time.month').mean(dim='time')\n",
    "obs_levels = np.flipud(Dair['level'].values)\n",
    "kobs = np.size(obs_levels)\n",
    "#\n",
    "# Interpolate u & v to Gaussian Grid\n",
    "#\n",
    "lnps_feb = isht(lnps_coeffs) # inverse tranform applied here to limit\n",
    "                             # unresolved scales\n",
    "ps_feb = (torch.exp(lnps_feb)*1000.0) # surface pressure in mb on Gaussian grid\n",
    "#\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(Duwnd.uwnd,dfoo,'bilinear')\n",
    "upress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "vpress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "airpress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "for k in range(kobs):\n",
    "    upress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(uwnd_clim[1,k])).values)\n",
    "    vpress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(vwnd_clim[1,k])).values)\n",
    "    airpress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(air_clim[1,k])).values) + 273.16\n",
    "#\n",
    "#\n",
    "# Interpolate from Pressure to Sigma Levels\n",
    "#\n",
    "usig_gg = press_to_sig(kobs,imax,jmax,upress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "vsig_gg = press_to_sig(kobs,imax,jmax,vpress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "tsig_gg = press_to_sig(kobs,imax,jmax,airpress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "tsig_gg = torch.where(tsig_gg < 205.0, 205.0, tsig_gg) ### This probably can be removed\n",
    "                                                    ### with improved vertical resolution\n",
    "#\n",
    "#\n",
    "# Need to apply forward and backward spectral transform to ensure that\n",
    "# there is no unresolved forcing from the prescribed background state\n",
    "#\n",
    "for k in range(kmax):\n",
    "    tmpspec = sht(usig_gg[k])\n",
    "    usig_gg[k] = isht(tmpspec)\n",
    "    tmpspec = sht(vsig_gg[k])\n",
    "    vsig_gg[k] = isht(tmpspec)\n",
    "    tmpspec = sht(tsig_gg[k])\n",
    "    tsig_gg[k] = isht(tmpspec)\n",
    "#\n",
    "# convert u & v into spectral vort & divergence\n",
    "#\n",
    "zmn,dmn = vortdivspec(vsht,usig_gg,vsig_gg,kmax,mw,zw)\n",
    "#\n",
    "# Transform Spectral Vorticity and Divergence to Gaussian Grid\n",
    "#\n",
    "vortsig_gg = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "divsig_gg = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "#\n",
    "coriolis = np.zeros((jmax,imax))\n",
    "for jj in range(jmax):\n",
    "    coriolis[jj,:] = (4.0*np.pi/86400)*np.sin(-lats[jj]*np.pi/180.0) # Minus sign (-lat)\n",
    "                                              # because grid runs South-to-North\n",
    "#\n",
    "f_spec = sht(torch.from_numpy(coriolis)) # f_spec is the spectral \n",
    "                                         # coriolis parameter\n",
    "for k in range(kmax):\n",
    "#    vortsig_gg[k,:,:] = isht(zmn[k]+f_spec) ### This is total vorticity\n",
    "    vortsig_gg[k,:,:] = isht(zmn[k]) ### This is relative vorticity\n",
    "    divsig_gg[k,:,:] = isht(dmn[k])\n",
    "#\n",
    "qmn = lnps_coeffs\n",
    "dxq_gg,dyq_gg = gradq(ivsht,qmn,mw,zw,imax,jmax)\n",
    "#\n",
    "#\n",
    "# Now write climo data\n",
    "#\n",
    "torch.save(usig_gg,preprocess_path+'usig.ggrid.pt')\n",
    "torch.save(vsig_gg,preprocess_path+'vsig.ggrid.pt')\n",
    "torch.save(tsig_gg,preprocess_path+'tsig.ggrid.pt')\n",
    "torch.save(vortsig_gg,preprocess_path+'vortsig.ggrid.pt')\n",
    "torch.save(divsig_gg,preprocess_path+'divsig.ggrid.pt')\n",
    "torch.save(dxq_gg,preprocess_path+'dxq_gg.ggrid.pt')\n",
    "torch.save(dyq_gg,preprocess_path+'dyq_gg.ggrid.pt')\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.pcolormesh(Lon, Lat, tsig_gg[6], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tsig_gg[:,45,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for k in range(kmax):\n",
    "    temp_gg[k] = isht(temp_coeffs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "footemp = tsig_gg - temp_gg\n",
    "plt.pcolormesh(Lon, Lat, tsig_gg[10], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "footemp = tsig_gg - temp_gg\n",
    "plt.pcolormesh(Lon, Lat, airpress_gg[3], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = usig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lon = np.meshgrid(-sl,lons)\n",
    "heating = heat[:,32,:]*86400\n",
    "foofoo = torch.transpose(heating, 0, 1)\n",
    "plt.pcolormesh(Lon, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(heat[:,33,70]*86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = vsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = vortsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, ps_feb, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, vortsig_gg[10], cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = divsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
