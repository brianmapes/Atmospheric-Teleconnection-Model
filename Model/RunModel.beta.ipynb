{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.captureWarnings(False)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)\n",
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=5, threads_per_worker=4, memory_limit='30GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import dask\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft as fft\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from sht_utils import *\n",
    "from subs1_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell initializes the model\n",
    "###\n",
    "###     First Define all spectral grids\n",
    "###\n",
    "zw = 42 # zonal wave number\n",
    "mw = 42 # meridional wave number\n",
    "kmax = 11\n",
    "imax = 128\n",
    "jmax = 64\n",
    "steps_per_day = 216 ### Changing this number impliws time step changes and should\n",
    "#                       be implemented carefully\n",
    "###\n",
    "spec = (mw,zw,kmax)\n",
    "grid = (imax,jmax,kmax)\n",
    "#\n",
    "#\n",
    "# provide experiment name and data path for writing out data\n",
    "# datapath may need to be edited for your system\n",
    "#\n",
    "expname = 'Control'\n",
    "foo = str(subprocess.check_output(['whoami']))\n",
    "end = len(foo) - 3\n",
    "uname = foo[2:end]\n",
    "datapath = '/Users/'+uname+'/Work/AGCM/AGCM/tmp4/'+expname+'/'\n",
    "subprocess.call(['rm','-r', datapath])\n",
    "subprocess.check_output(['mkdir', datapath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gaussian latitudes and equally spaced longitudes\n",
    "#\n",
    "cost_lg, wlg = legendre_gauss_weights(jmax, -1, 1)\n",
    "lats = np.flip(np.arccos(cost_lg))\n",
    "lats = -90+180*lats/(np.pi)\n",
    "#\n",
    "lons = np.linspace(0.0,360.0-360.0/imax,imax)\n",
    "#\n",
    "# Initialize grid to spectral (sht) and spectral to grid (isht)\n",
    "# transforms\n",
    "#\n",
    "sht = RealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "isht = InverseRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "vsht = RealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "ivsht = InverseRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "# Initialize spectral fields (at rest or to be read in)\n",
    "def initialize(f_spec,temp_newton,lnpsclim,kmax,mw,zw):\n",
    "    for k in range (kmax):\n",
    "        zmn1[k] = zmn1[k]+f_spec\n",
    "        tmn1[k] = tmn1[k] + temp_newton[k]\n",
    "        zmn2[k] = zmn2[k]+f_spec\n",
    "        tmn2[k] = tmn2[k] + temp_newton[k]\n",
    "        zmn3[k] = zmn3[k]+f_spec\n",
    "        tmn3[k] = tmn3[k] + temp_newton[k]\n",
    "    qmn1 = lnpsclim\n",
    "    qmn2 = lnpsclim\n",
    "    qmn3 = lnpsclim\n",
    "    return zmn1,zmn2,zmn3,tmn1,tmn2,tmn3,qmn1,qmn2,qmn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initialization: Could read spectral restarts, or could\n",
    "#              start at rest. If wanting to use grid point see\n",
    "#              jupyter notebook gptosp.agcm.ipynb\n",
    "#              \n",
    "#\n",
    "# Implement at rest initial condition, but need coriolis since\n",
    "# model predicts total vorticity\n",
    "#\n",
    "coriolis = np.zeros((jmax,imax))\n",
    "for jj in range(jmax):\n",
    "    coriolis[jj,:] = (4.0*np.pi/86400)*np.sin(-lats[jj]*np.pi/180.0)\n",
    "#\n",
    "f_spec = sht(torch.from_numpy(coriolis)) # f_spec is the spectral \n",
    "                                         # coriolis parameter\n",
    "#\n",
    "# Initialize spectral fields (at rest or to be read in)\n",
    "# Need to read in background temperature data for Newtonian\n",
    "# Relaxation and possible initialization, see gptosp.agcm.ipynb\n",
    "# for how to change source data or formulation.\n",
    "#\n",
    "temp_newton = torch.load('temp.spectral.pt') # newtonian \n",
    "#                                    relaxation temperature, spectral\n",
    "lnpsclim = torch.load('lnps.spectral.pt') # lnps climatology for damping\n",
    "#\n",
    "zmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "zmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "dmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "dmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "dmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "tmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "tmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "tmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "qmn1 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "qmn2 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "#\n",
    "zmn1,zmn2,zmn3,tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 =\\\n",
    "initialize(f_spec,temp_newton,lnpsclim,kmax,mw,zw)\n",
    "#\n",
    "# Topography data - this should be spectral data or can be\n",
    "#                        initialized to zero. If grid point data\n",
    "#                        is desired see gptosp.agcm.ipynb for how to\n",
    "#                        convert to spectral. \n",
    "#\n",
    "# Setting topography to zero here\n",
    "#\n",
    "###phismn = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# If non-zero topog read here\n",
    "#\n",
    "phismn = torch.load('topog.spectral.pt')\n",
    "#\n",
    "#\n",
    "# Adding heating here see preprocess.ipynb\n",
    "#\n",
    "heat = torch.load('heat.ggrid.pt')\n",
    "#\n",
    "# or set to zero\n",
    "#\n",
    "###heat = torch.zeros((kmax,jmax,imax),dtype=torch.complex128)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Constants, parameters, vertical differencing parameters,\n",
    "### matricies for geopotential height, etc ...\n",
    "###\n",
    "delsig, si, sl, sikap, slkap, cth1, cth2, r1b, r2b = bscst(kmax)\n",
    "### The above code is in subs1_utils.py - vertical structure related\n",
    "### This code would need to be changed if the vertical resolution\n",
    "### is changed - could be done by simply specifying delsig in bscst\n",
    "###\n",
    "amtrx, cmtrx, dmtrx = mcoeff(kmax,si,sl,slkap,r1b,r2b,delsig)\n",
    "### The above code is for geopotential height and implicit scheme\n",
    "### in subs1_utils.py but unlikely any changes would be needed\n",
    "emtrx = inv_em(dmtrx,steps_per_day,kmax,mw,zw)\n",
    "### The above code\n",
    "### emtrix is used in the implicit time scheme, computed once here to save cpu time\n",
    "### changes unlikely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preprocessing is complete - now time to run model\n",
    "#\n",
    "#\n",
    "# The Model Runs in 30-day chuncks - need to specify how many 30-day chunks to run\n",
    "tl = 30 ##### tl is the chunk size - typically 30 days, but for testing 3 is reasonable\n",
    "#\n",
    "# Suggested ichunk for time dependent models: 120\n",
    "#\n",
    "ae = 6.371E+06 # Earth radius\n",
    "tmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "zmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "dmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "qmnt = torch.zeros((tl,mw,zw),dtype=torch.complex128)\n",
    "wmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "ddtdiv = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "ddtvort = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "junk = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "ttend = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "vort = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "div = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "temp = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "qdot = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "times = pd.date_range(start = '1950-01-01', end='2100-01-01', freq='D')\n",
    "# \n",
    "ichunk = 12\n",
    "#\n",
    "idays = tl * ichunk\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Begin Time Loop\n",
    "#\n",
    "ii = 0\n",
    "savedat = 0\n",
    "daycount = 0\n",
    "total_days = 0\n",
    "nstep = idays*steps_per_day\n",
    "while ii < nstep:\n",
    "    ii = ii + 1\n",
    "    savedat = savedat + 1\n",
    "    if (savedat == steps_per_day): # post processing\n",
    "        #\n",
    "        # Call Postprocessing Routine as needed\n",
    "        #\n",
    "        zmnt[daycount] = zmn1\n",
    "        dmnt[daycount] = dmn1\n",
    "        tmnt[daycount] = tmn1\n",
    "        qmnt[daycount] = qmn1\n",
    "        wmnt[daycount] = wmn1\n",
    "        daycount = daycount + 1\n",
    "        total_days = total_days + 1\n",
    "        print(['Day = ',total_days])\n",
    "        if (daycount == tl):\n",
    "            times_30day = times[total_days-tl:total_days]\n",
    "            postprocessing(isht,ivsht,zmnt,dmnt,tmnt,qmnt,wmnt,\\\n",
    "                           phismn,f_spec,amtrx,times_30day,mw,zw,\\\n",
    "                           kmax,imax,jmax,sl,lats,lons,tl,datapath)\n",
    "            daycount = 0\n",
    "        savedat = 0\n",
    "    #\n",
    "    # Run model for one time step\n",
    "    #\n",
    "    # Spectral to grid transformation of needed fields:\n",
    "    #   Vorticity, divergence, temperature, U, V, \n",
    "    #   grad(ln(Ps)), Q prescibed heating\n",
    "    #\n",
    "    #\n",
    "    for k in range(kmax):\n",
    "        vort[k] = isht(zmn2[k]).cpu() ### This is the absolute vorticity\n",
    "        div[k] = isht(dmn2[k]).cpu()\n",
    "        temp[k] = isht(tmn2[k]).cpu()\n",
    "        qdot[k] = isht(wmn2[k]).cpu()\n",
    "    u,v = uv(ivsht,zmn2,dmn2,f_spec,mw,zw,kmax,imax,jmax)\n",
    "    dxq,dyq = gradq(ivsht,qmn2,mw,zw,kmax,imax,jmax)\n",
    "    #\n",
    "    # Non-Linear products\n",
    "    #\n",
    "    a,b,e,ut,vt,ri,wj,cbar,dbar = nlprod(u,v,vort,div,temp,dxq,dyq,heat,delsig,si,sikap,slkap,\\\n",
    "                                         r1b,r2b,cth1,cth2,cost_lg,kmax,imax,jmax)\n",
    "    #\n",
    "    #\n",
    "    # Grid to spectral transformation of nlprod results\n",
    "    #\n",
    "    ddtdiv,ddtvort = vortdivspec(vsht,a,b,kmax,mw,zw)\n",
    "    zmn3 = - ddtvort\n",
    "    dmn3 = ddtdiv\n",
    "    junk,ttend = vortdivspec(vsht,ut,vt,kmax,mw,zw)\n",
    "    for k in range(kmax):\n",
    "        dddt = dmn3[k] - lap_sht(sht,e[k],mw,zw) \n",
    "        dmn3[k] = dddt\n",
    "        tmn3[k] = -ttend[k] + sht(ri[k]).cpu()\n",
    "        wmn3[k] = sht(wj[k]).cpu() ### Prescribed heating converted to spectral\n",
    "    qmn3 = -sht(cbar).cpu() ### Only cbar here since dbar is included in implicit or explicit\n",
    "    # \n",
    "    # Diffusion, Damping, Implicit or Explicit time differencing, Time filter\n",
    "    #\n",
    "    zmn3,dmn3,tmn3 = diffsn(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,\\\n",
    "                            kmax,mw,zw)\n",
    "    #\n",
    "    zmn3,dmn3,tmn3,qmn3 = damp(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,qmn1,qmn3,\\\n",
    "                          f_spec,temp_newton,lnpsclim,kmax)\n",
    "    #\n",
    "    dt = 86400.0/steps_per_day\n",
    "    #\n",
    "    zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 = \\\n",
    "                        explicit(dt,amtrx,cmtrx,dmtrx,emtrx,\\\n",
    "                        zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,\\\n",
    "                        tmn3,wmn1,wmn2,wmn3,qmn1,qmn2,qmn3,phismn,\\\n",
    "                        delsig,kmax,mw,zw)\n",
    "    ####\n",
    "    ## Reset zmn3, dmn3, tmn3,wmn3 & qmn3\n",
    "    ###\n",
    "    zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    dmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    tmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    wmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
